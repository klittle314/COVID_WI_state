---
title: 'Gating Criterion:  Per cent Daily Positive Tests'
author: "Kevin Little,Ph.D., Informing Ecological Design, LLC"
date: '`r format(Sys.time(), "%B %d, %Y")`'
output:
  pdf_document: default
  word_document: default
  html_document: default
---

### Gating Criteria from Wisconsin State DHS:  Lifting Stay at Home Restrictions
Symptoms: 	Downward trajectory of influenza-like illnesses (ILI) reported within a 14-day period. 	

Symptoms: 	Downward trajectory of COVID-like syndromic cases reported within a 14-day period. 	

Cases: 	Downward trajectory of positive tests as a percent of total tests within a 14-day period. 	

Hospitals:  Criteria are currently under development in partnership with Wisconsin healthcare stakeholders.

See [**DHS website**](https://www.dhs.wisconsin.gov/covid-19/prepare.htm) for the criteria and the State 'Badger Bounce Back Plan' [**here**](https://www.dhs.wisconsin.gov/publications/p02653.pdf) that puts the criteria in context.

#### What is this document?

The document offers plots to inform DHS understanding and action related to the 'Cases' gating criterion.

We recommend daily review of a set of plots

1. raw test data of new positives, new negatives, new total, and per cent of new positive cases

2. slope of per cent new positive cases from 14 day intervals, related to the gating criterion.  Using the proposed criterion of negative slope from a linear regression based on 14-day period, we construct a graph that shows slopes for consecutive 14 day windows. When the upper 95% confidence interval is negative, the trajectory criterion is met. 

3. A control chart of the per cent positive tests to track the per cent positive tests, to reveal signals of special cause(s) in the per cent plot. A control chart that incorporates both within day variation in the per cent positive test and day to day variation in testing encourages DHS decision-makers to understand daily and weekly patterns in the per cent positive test measure.  The control charts show an additional criterion, daily per cent positive tests should be at or below 5%.


### Testing Data:  Plots of Daily Counts
```{r setup, include=FALSE}
library(readr)
library(tidyverse)
library(GGally)
library(gridExtra)
library(data.table)

knitr::opts_chunk$set(echo = FALSE)

#set up the file, filepath and data directory
data_file_stateWI <- paste0('data/WI_state_data_', as.character(Sys.Date()), '.csv')

data_csv <- "https://opendata.arcgis.com/datasets/b913e9591eae4912b33dc5b4e88646c5_10.csv"

ifelse(!dir.exists('data'), dir.create('data'), FALSE)

if(!file.exists(data_file_stateWI)) {
  data1 <- try(fread(data_csv))
  write_csv(data1, path=data_file_stateWI)
}

if(file.exists(data_file_stateWI)) {
  #GEOID is a state, county and census tract code
  #GEOID: 55=State of Wisconsin; 55001:55141 for counties (odd numbers only)                                                
  #census tract ids are then of the form 55xxxyyyyyy
  #Missing census tract id will be stated as TRACT N/A so GEOID is assigned as character type for now
  df_in <- read_csv(data_file_stateWI, col_types=cols(.default = 'i',
                                                    GEOID = 'c',
                                                    GEO = 'c',
                                                    NAME = 'c',
                                                    LoadDttm = 'c'))
  #date time format of the state file seems to have changed on 6 May 2020
  #records have form "2020/03/15 19:00:00+00".  So strip off +00 and convert to date-time object
  df_in$Date_time <- as.POSIXct(gsub("\\+00","",df_in$LoadDttm))
  df_in$Date_reported <- as.Date(df_in$Date_time, tz = "US/Central")

}
#pull state and county records
df1 <- df_in %>% filter(GEO %in% c('State','County'))


#distinguish baseline from most recent 14 days
cut_date <- max(df1$Date_reported) - 14

df1$phase <- ifelse(df1$Date_reported <= cut_date,"baseline","last 14 days")

df1_state <- df1 %>% select(GEOID,GEO,NAME,Date_reported,NEGATIVE,POSITIVE) %>% filter(GEO == 'State')
df1_state$NEGATIVE[df1_state$Date_reported == as.Date("2020-03-29")] <- 15856
df1_state$NEGATIVE[df1_state$Date_reported == as.Date("2020-03-30")] <- 16550

#now extract only the overall testing numbers and create daily counts
df1_state <- df1_state %>%
                      group_by(NAME) %>% 
                      mutate(lag_POSITIVE = lag(POSITIVE)) %>% mutate(POSITIVE_daily = POSITIVE - lag_POSITIVE) %>%
                      mutate(lag_NEGATIVE = lag(NEGATIVE)) %>% mutate(NEGATIVE_daily = NEGATIVE - lag_NEGATIVE) %>%
                      mutate(Total_daily_tests = POSITIVE_daily + NEGATIVE_daily) %>%
                      mutate(POS_pct_daily = 100*(POSITIVE_daily/Total_daily_tests)) 

#Now break the series into 14 day periods and compute slope and find 95% interval
#take a data series and return slope and end points of 95% CI
daycode0 <- seq.int(from = 0,to = 13, by = 1)

#function to calculate slope, intercept and confidence interval for a regression on 14 days of data
slope_pars <- function(dfx,daycode=daycode0) {
  list_out <- list()
  
  lm1 <- lm(dfx$POS_pct_daily ~ daycode)
  
  list_out$slope <- lm1$coefficients[2]
  
  list_out$intercept <- lm1$coefficients[1]
  
  list_out$conf_int <- confint(lm1,'daycode',level= 0.95)
  
  return(list_out)
}


#sequence of dates:  allow for change in dates
start_date <- min(df1_state$Date_reported)
end_date <- max(df1_state$Date_reported) - 13
date_seq <- seq.Date(from = start_date, to = end_date, by = "day")

#function to return the linear regression parameters as a 1 row dataframe
get_slope_pars <- function(dfx,date_start,daycode) {
  df_use <- dfx %>% filter(Date_reported >= date_start & Date_reported <= date_start + 13)
  ls <- slope_pars(dfx = df_use,daycode = daycode)
  df_slope_pars <- data.frame(ls$intercept,
                              ls$slope,
                              ls$conf_int[1],
                              ls$conf_int[2])
  names(df_slope_pars) <- c("intercept","slope", "LCI","UCI")
  row.names(df_slope_pars) <- NULL
  return(df_slope_pars)
}

#now assemble the slopes for the dates, starting with the first 14 days of the data table
list_df_slope_pars <- lapply(date_seq,get_slope_pars,dfx = df1_state, daycode = daycode0)
  
df_slopes <- do.call(rbind, list_df_slope_pars)

df_slopes$Date_end <- date_seq + 13

paste0('Data file used is ', data_file_stateWI)
#knitr::kable(head(df1_small_state))
```

`r paste0('Data file used is ', data_csv)`

`r paste0('Date-time stamp of most recent record is ', as.character(max(df1$Date_time,na.rm=TRUE)))`

```{r initial_plots, echo=FALSE, warning=FALSE, message=FALSE, fig.height=8}
#distinguish baseline from most recent 14 days
cut_date <- max(df1_state$Date_reported) - 14

df1_state$phase <- ifelse(df1_state$Date_reported <= cut_date,"baseline","last 14 days")

df1_state_longer <- df1_state %>% 
                      select(GEO,NAME,Date_reported,POSITIVE_daily,NEGATIVE_daily,Total_daily_tests,POS_pct_daily,phase) %>%
                      pivot_longer(cols = -c("GEO","NAME","Date_reported","phase"),
                                               names_to = "Measure",
                                               values_to = "value")

dfA <- df1_state_longer %>% filter(Measure %in% c('NEGATIVE_daily','POS_pct_daily','POSITIVE_daily','Total_daily_tests'))
dfA$Measure <- factor(dfA$Measure, levels=c("POSITIVE_daily", 'NEGATIVE_daily','Total_daily_tests','POS_pct_daily'))

#create medians
med_A <- as.vector(tapply(dfA$value,dfA$Measure, median, na.rm=TRUE))
Measure <- levels(dfA$Measure)
df.hlines <- data.frame(Measure, med_A)

p1 <- ggplot(data=dfA,aes(x=Date_reported,y=value))+
        theme_bw()+
        geom_point(aes(shape=phase))+
        facet_wrap(~Measure,
                   ncol = 1,
                   scales = 'free_y')+
        labs(title="Test counts",
             subtitle="Dashed lines are medians for entire series")+
        geom_hline(aes(yintercept=med_A),data=df.hlines,lty=2)+
        ylab("")+
        xlab("Date Reported")+
        annotate("rect", fill = "blue", alpha = 0.1, 
            xmin = cut_date + .5, xmax = max(dfA$Date_reported)+.5,
            ymin = -Inf, ymax = Inf)+
        scale_shape_discrete(na.translate=FALSE)+
         theme(legend.position = c(0.15, 0.99),
              legend.justification = c("right", "top"),
              legend.text = element_text(size = 6),
              legend.title= element_text(size = 8))

p1 

```

```{r  slope_plot, echo=FALSE,message=FALSE}


ptest <- ggplot(data=df_slopes,aes(x=Date_end,y=slope))+
        theme_bw()+
        geom_point()+
        labs(title = 'Slope of Pct Positive Tests: 14 day windows',
             subtitle = "The slope plotted for each day is the slope from the linear fit of \n pct positive daily tests in a 14 day window ending at the day's date",
             caption = '95 percent confidence interval limits for each slope marked by *')+
        geom_point(aes(x=Date_end,y=LCI),shape=8)+
        geom_point(aes(x=Date_end,y=UCI),shape=8)+
        geom_hline(yintercept=0) +
        #ylim(-1,1)+
        xlab("")+
        ylab("")

ptest


```
By construction, the series of daily slopes is highly serially correlated, as adjacent days share 13 observations in calculation of the slope of new cases.   The reference line at 0 indicates a slope of zero.   To meet the gating criterion, the upper star for a day must be below the reference line.

### Control Chart view:  Daily Percent Positive Tests 
Compute control limits shown via three options:

1. specify all variation as within day (p-chart structure, binomial variation).

2. specify all variation as between days (individuals chart structure, point to point variation using standard control chart scaling)

3. allow variation as combination of within and between day variation per D.B. Laney ((2002), “Improved Control Charts for Attributes,” *Quality Engineering*, **14**(4), 531–537).

As the number of daily tests will likely continue to increase, it makes sense to account for variation in count size.  My current vote is option 3.

In any approach, calculate the control chart center line (average) and the limits using a baseline data series 14 records shorter than the entire record.

Extend the center line and limits based on the baseline calculations.  Examine the chart for signals of special causes of variation.

Plot the 5% gating level to examine relationship of current positive rate to the 5% level.

If there are no special cause signals, on the next day, extend the baseline by 1 day. 

Repeat.

The charts shown here use all days between 25 March and 15 days before the last date of the data series as baseline.  If there are signals of special causes, the limits should be frozen; code can/will be revised to include logic to catch special causes and freeze the limits.

```{r control_charts, echo=FALSE, warning=FALSE, message=FALSE, fig.height=4}
df0 <- df1_state %>% filter(Date_reported >= as.Date("2020-03-25"))

df0$pi <- df0$POS_pct_daily/100

df0_baseline <- df0 %>% filter(Date_reported <= max(Date_reported) - 14)

#compute binomial limits
df0$qi <- 1 - df0$pi
p_bar <-sum(df0_baseline$POSITIVE_daily)/sum(df0_baseline$Total_daily_tests)
df0$sigma_pi <- sqrt(p_bar*(1-p_bar)/df0$Total_daily_tests)
df0$p_UCL <- p_bar + 3*df0$sigma_pi
df0$p_LCL <- p_bar - 3*df0$sigma_pi

#compute z scores and assess variation in z scores
df0$zi <- (df0$pi - p_bar)/df0$sigma_pi
Rzi <- abs(diff(df0$zi[df0$Date_reported <= max(df0$Date_reported)-14]))
sigma_zi <- mean(Rzi)/1.128
df0$Laney_sigma <- df0$sigma_pi*sigma_zi
df0$pprime_LCL <- p_bar - 3*df0$Laney_sigma
df0$pprime_UCL <- p_bar + 3*df0$Laney_sigma

#compute I chart values
p_barI <- mean(df0_baseline$pi)  #assumes equal weighting of the Lot proportions
Rpi <- abs(diff(df0_baseline$pi))
sigma_aver_Rpi <- mean(Rpi)/1.128
sigma_median_Rpi <- median(Rpi)/0.9554

pchart <- ggplot(data=df0,aes(x=Date_reported,y=100*pi)) +
  theme_bw()+
  geom_point(aes(shape=phase),size=rel(2))+
  geom_line()+
  labs(title="p control chart for Pct Positive tests",
       x=" ",
       y="%",
       subtitle="Limits based on binomial variation, scaled by daily n; baseline period unshaded") +
  geom_hline(yintercept=100*p_bar)+
  geom_line(aes(x=Date_reported,y=100*p_LCL),linetype='dashed')+
  geom_line(aes(x=Date_reported,y=100*p_UCL),linetype='dashed')+
  geom_hline(yintercept= 5, colour="blue",lty="dotted")+
  ylim(0,20)+
  annotate("rect", fill = "blue", alpha = 0.1, 
        xmin = cut_date + .5, xmax = max(df0$Date_reported)+.5,
        ymin = -Inf, ymax = Inf)+
  scale_shape_discrete(na.translate=FALSE)+
         theme(legend.position = c(0.99, 0.99),
               legend.justification = c("right", "top"),
               legend.text = element_text(size = 6),
               legend.title= element_text(size = 8))

pchart

#ichart
ichart <-ggplot(data=df0,aes(x=Date_reported,y=100*pi)) +
  theme_bw()+
  geom_point(aes(shape=phase),size=rel(2))+
  geom_line()+
  labs(title="Individuals control chart for Pct Positive tests",
       x="",
       y="%",
       subtitle="Limits based between day variation ignoring test counts; baseline period unshaded") +
  geom_hline(yintercept=100*p_barI)+
  geom_hline(yintercept= 5, colour="blue",lty="dotted")+
  ylim(0,20)+
  annotate("rect", fill = "blue", alpha = 0.1, 
        xmin = cut_date + .5, xmax = max(df0$Date_reported)+.5,
        ymin = -Inf, ymax = Inf)+
  scale_shape_discrete(na.translate=FALSE)+
         theme(legend.position = c(0.99, 0.99),
              legend.justification = c("right", "top"),
              legend.text = element_text(size = 6),
              legend.title= element_text(size = 8))

ichart_Median <- ichart+ geom_line(aes(x=Date_reported,y=100*(p_barI - 3*sigma_median_Rpi)),linetype='dashed')+
  geom_line(aes(x=Date_reported,y=100*(p_barI + 3*sigma_median_Rpi)),linetype='dashed')+
  labs(caption="Limits based on median moving range")
#ichart_Median

ichart_Mean <- ichart+ geom_line(aes(x=Date_reported,y=100*(p_barI - 3*sigma_aver_Rpi)),linetype='dashed')+
  geom_line(aes(x=Date_reported,y=100*(p_barI + 3*sigma_aver_Rpi)),linetype='dashed') +
  labs(caption="Limits use average moving range; option is to use median moving range")
ichart_Mean

#make p prime chart
pprime_chart <-ggplot(data=df0,aes(x=Date_reported,y=100*pi)) +
  theme_bw()+
  geom_point(aes(shape=phase),size=rel(2))+
  geom_line()+
  labs(title="p' control chart for Pct Positive",
       x="",
       y="%",
       subtitle="Limits based on Laney calculations; baseline period unshaded") +
  geom_hline(yintercept=100*p_bar)+
  geom_line(aes(x=Date_reported,y=100*pprime_LCL),linetype='dashed')+
  geom_line(aes(x=Date_reported,y=100*pprime_UCL),linetype='dashed')+
  geom_hline(yintercept= 5, colour="blue",lty="dotted")+
  ylim(0,20)+
  scale_shape_discrete(na.translate=FALSE)+
         theme(legend.position = c(0.99, 0.99),
              legend.justification = c("right", "top"),
              legend.text = element_text(size = 6),
              legend.title= element_text(size = 8))+
  annotate("rect", fill = "blue", alpha = 0.1, 
        xmin = cut_date + .5, xmax = max(df0$Date_reported)+.5,
        ymin = -Inf, ymax = Inf)
                
pprime_chart

#number of tests per day
ptests <- ggplot(data=df0,aes(x=Date_reported,y=Total_daily_tests))+
          theme_bw()+
          geom_point(aes(shape=phase),size=rel(2))+
          geom_line()+
          labs(title="Total Daily Tests",
            subtitle="Baseline Median Daily Tests, dashed line",
            x="",
            y="")+
      geom_hline(yintercept=median(df0$Total_daily_tests[df0$Date_reported <= cut_date]),lty="dashed")+
      annotate("rect", fill = "blue", alpha = 0.1, 
        xmin = cut_date + .5, xmax = max(df0$Date_reported)+.5,
        ymin = -Inf, ymax = Inf)+
      scale_shape_discrete(na.translate=FALSE)+
         theme(legend.position = c(0.05, 0.99),
              legend.justification = c("left", "top"),
              legend.text = element_text(size = 6),
              legend.title= element_text(size = 8))
 
ptests



```

### Note on independence assumption

If there are clusters of positive cases violating the independence assumptions for within day variation, this will tend to lead to 'Criterion 1' signal on the control chart; the effective number of observations is reduced in the presence of clusters, which implies that the limits based on independence will be narrower than is the case.

